---
title: 'Scenario 3: Having strong and detailed a priori assumptions'
output:
  html_document:
    df_print: paged
  pdf_document: default
---
Kumle, L., Vo, M. L-H., & Draschkow, D.

latest update: March 2020

***



This notebook supplements Scenario 3 in Kumle, Vo & Draschkow (in preparation) - where detailed theoretical background concerning the analyses can be found.


For a general introduction to simulation-based power analyses as well as using simulations to explore power for different sample sizes, see [Scenario 1](https://lkumle.github.io/power_notebooks/Scenario1_notebook.html). Simulations focusing on exploring power for different number of stimuli or combinations of stimuli and subjects can be found in [Scenario 2](https://lkumle.github.io/power_notebooks/Scenario2_notebook.html).

***


Simulation-based power analyses for (generalized) linear mixed models typically require a fitted model to inform the simulation. To fit a model, however, we need appropriate data that inform the model parameters. The simulations in Scenario 1 and 2 always made use of already existing data  - but what if appropriate data is not available from previous research?

In the following notebook, we will focus on scenarios where no previous data exists or a researcher already has substantiated expectations of effect sizes, data and model structure. In such cases, it is possible to build data and model from scratch to bypass the lack of appropriate existing data. To do so, we will make use of the [*simr*](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12504) package (Green & Macleod, 2016) as well as the [*mixedpower* ](https://github.com/DejanDraschkow/mixedpower) package (Kumle, Vo & Draschkow, 2018).

This approach comes with a range of theoretical concerns which can be found in the accompanying tutorial (Kumle, Vo & Draschkow, in preparation). We strongly recommend getting familiar with those concerns as well as how they effect the power of the resulting design.

***
***

### Creating artificial data

Before we can think about building a model from scratch, we need to create artificial data containing all relevant variables and covariates.
Let’s assume we are planning a study investigating the effect of native language (English vs. non-English) in a lexical decision task (i.e. participants are asked to decide if displayed letters form a word or not) where English and non-English words are presented. Besides native language, we are also interested in the effect of how common a displayed word is in the English language (i.e. word frequency) as well as the interaction between both and plan to measure reaction times/speed as the dependent variable. Accordingly, we plan to analyze their data with a linear mixed model including native language and word frequency as fixed effects as well as including intercepts for subject and stimuli (i.e. word) as random effects. The formula for such a model therefore will be:

```{r}
# formula for artificial model
formula <- speed ~ NativeLanguage * Frequency + (1 | Subject) + (1 | Word)
```

From this formula, we can now derive which variables we need to specify in our artificial data.

&nbsp;  

##### **Random effects**

Starting with the random effects, we need variables containing subject and stimuli identifier. We can change this number in our power analysis later and will start with a data set containing 20 subjects each of whom reads 100 words.

```{r}
# 1. create subject IDs  -> let's start with 20 subjects
subject_ID <- (1:20)

# 2. create stimuli IDS -> every subject should read 100 words
stimuli_ID <- (1:100)
```

Using **expand.grid()**, we can create a data frame with all combinations of the supplied vectors.
```{r}
# 3. combine subject IDs and stimui IDs
artificial_data <- expand.grid(Word = stimuli_ID, Subject = subject_ID)
```
&nbsp;  

##### **Fixed effects**

Next, we need to include the fixed effects *native language* and *frequency*.
Let’s start with native language, which we agreed to have two levels (English vs. Non-English). We will code those two levels using the labels -0.5 for English speakers and 0.5 for Non-English speakers and will keep both groups balanced (i.e. including as many English speakers as Non-English speakers in our sample) - this, however, is an assumption we need to give some thought as unbalanced groups lead to reduced power (Kumle, Vo & Draschkow, in preparation) and should therefore match our planned recruiting efforts.

```{r}
# 1. create vector including identifier for native language
native_language <- c(rep(-0.5, 1000), rep(0.5, 1000))

# --> we will have 10 subjects in every group, each of whom reads 100 words
# --> the vector needs to contain 1000 "-0.5" and 1000 "0.5" entries

# 2. add vector to data set
artificial_data["NativeLanguage"] <- native_language
```

In a next step, we will generate frequency ratings for our second fixed effect. Since they will heavily influence our data structure, we need to be able to justify which frequency ratings we use. Ideally, we would already have actual frequency ratings on hand or know the frequencies’ distribution from which we can sample. In this example, we choose to sample from a normal distribution with a mean of 5 and s standard deviation of 1.

```{r}
#  1. generate frequency ratings
frequency_ratings <- rnorm(100, mean = 5, sd = 1) # draw 100 frequency rating (one for every word)

# 2. add to data frame
artificial_data["Frequency"] <- rep(frequency_ratings, 20) # multiply by 20 (for every subject)
```


***
***
### Building a model from scratch

&nbsp;  
Now that we created an artificial data set, we can use it as the basis to create our model. However, as we do not have measures for our dependent variable *speed*, we cannot simply use the *lmer() - function* in [*lme4*](https://arxiv.org/pdf/1406.5823.pdf) (Bates, Maechler, Bolker & Walker, 2015) to fit the model. Instead, we will make use of the **makeLmer()** and **makeGlmer()** function provided by [*simr*](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12504) package (Green & Macleod, 2016).  

```{r message=FALSE, warning=FALSE}
library(simr)
```

Since we can’t actually fit the model to the structure of our data, we need to build the structure ourselves instead. This includes specifying values for the beta coefficients, variance of the random effects and the error variance (i.e. sigma).  Deciding on those values represents the most important step in this scenario, since they will ultimately inform our subsequent simulation.  Being able to justify them therefore is extremely important.

First, we will specify values for our beta coefficients. This includes a value for the intercept as well as for all interactions included in a model. In our example, we therefore need to decide on a value for the intercept, the effects of *native language* and *frequency* as well as their interaction.  

```{r}

# ------------------------------------------ #
# SPECIFY BETA COEFFICIENTS FOR FIXED EFFECTS
fixed_effects <- c(1.7, -0.25, 0.02, 0.03) # order follows the order in model summary and formula
```

Second, we need to specify the variance of the random effects (i.e. subject and stimuli). Since we have more than one random effect, we need to provide them in a list - their order follows the order in the model formula specified earlier.

```{r}

# ------------------------------------------ #
# SET RANDOM INTERCEPT VARIANCE
random_variance <- list(0.007, 0.05)
```
&nbsp;  

##### **Create Lmer**

Since we are interested in the speed of people's reactions, which is a continuous measurement, a linear mixed model (LMM) is the right choice. Therefore, we will make use of the **makeLmer** function first. Later, we will focus on situations in which we want to create a generalized linear mixed model (GLMM).

To do so, we also need to specify the residual standard deviation (i.e. sigma) - which heavily influences the power of the resulting model with higher sigma leading to lower power (Kumle, Vo & Draschkow, in preparation).

```{r}

# ------------------------------------------ #
# SET RESIDUAL STANDARD DEVIATION
sigma <- 0.26
```

Now we can hand all parameters to the *makeLmer()-function*.
```{r}

# ------------------------------------------ #
# CREATE LMER
artificial_lmer <- makeLmer(formula = Speed ~ NativeLanguage * Frequency + (1 | Subject) + (1 | Word),
                           fixef = fixed_effects, VarCorr = random_variance, sigma = sigma,
                           data = artificial_data)

# lets have a look!
summary(artificial_lmer)
```
&nbsp;  

#### **Create Glmer**

While we will keep our focus on conducting a power analysis for the LMM create above, we will have a quick look at creating GLMMs. All following steps regarding the power analysis are the same for LMMs and GLMMs  - being able to fit a GLMMs from scratch therefore is the only difference in this process. We can create a GLMM using the **makeGlmer()** function - instead of specifying a residual standard deviation (sigma), however, we will state the *family* of our GLMM.

Imagine instead of speed we would model a variable indicating if subjects correctly classified a word in our lexical decision task. In this case, we would have a binary dependent variable that we will call “correct”. Keeping all fixed and random effects the same, the formula for our GLMM would look like this:

```{r}

# ------------------------------------------ #
# formula for GLMM
formula_glmer <- Correct ~ NativeLanguage * Frequency + (1 | Subject) + (1 | Word)
```

Since we already specified the beta coefficients and random effect variances earlier, we can simply hand all information to the *makeGlmer()* function. Note how we specified “binomial” as the model’s family.

```{r}

# ------------------------------------------ #
# create GLMM
artificial_glmer <- makeGlmer(formula = Correct ~ NativeLanguage * Frequency + (1 | Subject)+ (1 | Word),
                              family = "binomial", fixef = fixed_effects,
                              VarCorr = random_variance, data = artificial_data)

# lets have a look!
summary(artificial_glmer)
```
***
***

### Power analysis


Now that we have data and a model fit to it we can start with the actual power analysis. Since the power simulation from this point onwards follows the same steps as in [Notebook 1](https://lkumle.github.io/power_notebooks/Scenario1_notebook.html) and [Notebook 2](https://lkumle.github.io/power_notebooks/Scenario2_notebook.html), we will only focus on a simple power simulation. More complex simulations varying different parameters can be found in the preceding notebooks.
&nbsp;  

##### **simr**
Using the **powerSim()** function provided by [*simr*](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12504) (Green & Macleod, 2016), we can simulate power for exactly the parameter constellation handed into the simulation. All we have to specify is the model we want to simulate power for and, since simr can only simulate power for one effect at a time, the effect we want to test.

```{r eval = F}

# ------------------------------------------ #
# POWER ANALYSIS WITH SIMR
power_simr <- powerSim(artificial_lmer, test= fixed("NativeLanguage"))
```

```{r include=FALSE}
# load output in the background
load("~/Dropbox/Power/manuscript/BRM/analyses_BRM/Scenario 3/S3_simr_NL.Rdata")

```

Let's have a look at the result: As we can see, including 20 subjects, each of whom reads 100 words, and the model parameter specified earlier result in a power of around 54%.
```{r}

# ------------------------------------------ #
# let's have a look:
print(power_simr)
```
Using *powerSim()* gave us a point estimate for one specific constellation of parameters. However, this is of limited use in cases where we want to explore power for a range of parameter constellation to make an informed decision about our research design. To explore different scenarios, we could change the model parameters while we set up the artificial data and repeat the power analysis with *powerSim()*. Alternatively, we can make use of simulation functions that can complete this task for us.

&nbsp;  

##### **mixedpower**

Naturally, we can also implement a power simulation with mixedpower and make use of its faster computational speed and the fact that it estimates power for all included effects simultaneously.
Using **mixedpower()**,  we will conduct a quick power analysis exploring power for different sample sizes. Similar to [Notebook 1](https://lkumle.github.io/power_notebooks/Scenario1_notebook.html) and [Notebook 2](https://lkumle.github.io/power_notebooks/Scenario2_notebook.html), we will assign all parameters explicitly first.
```{r eval=FALSE}

# ------------------------------------------ #
# INFORMATION ABOUT MODEL USED FOR SIMULATION

model <- artificial_lmer # which model do we want to simulate power for?
data <- artificial_data # data used to fit the model
fixed_effects <- c("NativeLanguage", "Frequency") # all fixed effects specified in FLPmodel
simvar <- "Subject" # which random variable do we want to vary in the simulation?

# ------------------------------------------ #
# SIMULATION PARAMETERS
steps <- c(20,30,40,50,60,70,80) # which sample sizes do we want to look at?
critical_value <- 2 # which t/z value do we want to use to test for significance?
n_sim <- 1000 # how many single simulations should be used to estimate power?

# ------------------------------------------ #
# INCLUDE SESOI SIMULATION
SESOI <- c(1.7, -0.2, 0.017, 0.027) # specify SESOI
```
&nbsp;    
Note how we included a SESOI (i.e. smallest effect of interest) simulation. Even though the effect sizes are not coming from published data (which come with the risk of inflated effect sized) and we would optimally have specified SESOIs as our fixed effects already, this gives us the chance to estimate power for different possible effect sizes in the course of one simulation.
&nbsp;

Now, we will hand all parameters to the simulation function and wait for the results.

```{r eval = F}
# ------------------------------------------ #
# RUN SIMULATION WITH MIXEDPOWER
power <- mixedpower(model = FLPmodel, data = YanData,
                       fixed_effects = c("word_length", "complexity"),
                       simvar = "subject", steps = c(20,30,40,50,60,70,80),
                       critical_value = 2, n_sim = 1000,
                       SESOI = c(1.7, -0.2, 0.017, 0.027))

# ------------------------------------------ #
# PLOT THE RESULTS
multiplotPower(power)
```

```{r include=FALSE}
# load output in the background
load("~/Dropbox/Power/manuscript/BRM/analyses_BRM/Scenario 3/S3_mixedpower.Rdata")

```

```{r}
# ------------------------------------------ #
# RUN SIMULATION WITH MIXEDPOWER
power
```

```{r eval = F}
# ------------------------------------------ #
# PLOT THE RESULTS
multiplotPower(power)
```

![](/Users/leah/Dropbox/Power/manuscript/BRM/analyses_BRM/Scenario 3/plot_mixedpower_S3.png)

&nbsp;  

Finally, we need to transfer the plots and results into a decision regarding the sample size of our planned study. General guidance can be found in the accompanying tutorial paper. In this notebook, we will adapt a strategy resulting in > 80% power for all effects included in the model.
Depending on which effect sizes we base our decision, we would either test 50 subjects (databased estimate) or 70 subjects (SESOI estimate) - each of whom would be presented with 100 stimuli.

&nbsp;   

However, we strongly encourage users to simulate power for a range of plausible parameters concerning the artificial data as well as different levels of random effects to get an overview of factors that influence power in the planned design.

***
***

### References

Bates, D., Maechler, M., Bolker, B., & Walker, S. (2014). Fitting Linear Mixed-Effects Models using lme4. Journal of Statistical Software, 67(1). https://doi.org/10.18637/jss.v067.i01

Green, P., & Macleod, C. J. (2016). SIMR: An R package for power analysis of generalized linear mixed models by simulation. Methods in Ecology and Evolution, 7(4), 493-498. [https://doi.org/10.1111/2041-210X.12504](https://doi.org/10.1111/2041-210X.12504)

Kumle, L., Vo, M. L-H., & Draschkow, D. (2018). Mixedpower: a library for
estimating simulation-based power for mixed models in R. https://doi.org/10.5281/zenodo.1341047

Kumle, L., Vo, M. L-H., & Draschkow, D. (in preparation). Estimating power in linear and generalized linear mixed models: an open introduction and tutorial in R.
